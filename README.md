# CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation

Weixiang Yan<sup>1âˆ—</sup>, Haitian Liu<sup>2âˆ—</sup>, Yunkun Wang<sup>3âˆ—</sup>, Yunzhe Li<sup>4âˆ—</sup>, Qian Chen<sup>5</sup>,
Wen Wang<sup>5</sup>, Tingyu Lin<sup>6</sup>, Weishan Zhao<sup>7</sup>, Li Zhu<sup>2</sup>, Shuiguang Deng<sup>3</sup>, Hari Sundaram<sup>4</sup>

<sup>1</sup>University of California, Santa Barbara<br>
<sup>2</sup>Xiâ€™an Jiaotong University<br>
<sup>3</sup>Zhejiang University<br>
<sup>4</sup>University of Illinois at Urbana-Champaign<br>
<sup>5</sup>Speech Lab, Alibaba Group<br>
<sup>6</sup>TU Wien<br>
<sup>7</sup>University of Chinese Academy of Sciences<br>
<sup>âˆ—</sup>Equal contribution<br>

<p align="center" width="80%">
<img src="static/img/logo-2.png" style="width: 40%; min-width: 300px; display: block; margin: auto;" alt="CodeScope">
</p>

<p align="center">
    ğŸ“ƒ <a href="" target="_blank">Paper</a> | 
    ğŸŒ <a href="" target="_blank">Website</a> | 
    ğŸ¤— <a href="" target="_blank">HuggingFace</a> | 
    ğŸ’­ <a href="" target="_blank">Google Drive</a>
</p>