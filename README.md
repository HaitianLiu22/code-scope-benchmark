# CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation

Weixiang Yan<sup>1∗</sup>, Haitian Liu<sup>2∗</sup>, Yunkun Wang<sup>3∗</sup>, Yunzhe Li<sup>4∗</sup>, Qian Chen<sup>5</sup>,
Wen Wang<sup>5</sup>, Tingyu Lin<sup>6</sup>, Weishan Zhao<sup>7</sup>, Li Zhu<sup>2</sup>, Shuiguang Deng<sup>3</sup>, Hari Sundaram<sup>4</sup>

<h6><sup>∗</sup>Equal contribution</h6>
<h6><sup>1</sup>University of California, Santa Barbara</h6>
<h6><sup>2</sup>Xi’an Jiaotong University</h6>
<h6><sup>3</sup>Zhejiang University</h6>
<h6><sup>4</sup>University of Illinois at Urbana-Champaign</h6>
<h6><sup>5</sup>Speech Lab, Alibaba Group</h6>
<h6><sup>6</sup>TU Wien</h6>
<h6><sup>7</sup>University of Chinese Academy of Sciences</h6>

<p align="center" width="80%">
<img src="static/img/logo-2.png" style="width: 40%; min-width: 300px; display: block; margin: auto;" alt="CodeScope">
</p>

<p align="center">
    📃 <a href="" target="_blank">Paper</a> | 
    🌐 <a href="" target="_blank">Website</a> | 
    🤗 <a href="" target="_blank">HuggingFace</a> | 
    💭 <a href="" target="_blank">Google Drive</a>
</p>